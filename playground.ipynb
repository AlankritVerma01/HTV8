{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, requests, json, openai, PyPDF2, pdfplumber, re, tiktoken\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from io import BytesIO\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "pdf_file = \"attention.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class SectionNode:\n",
    "\n",
    "    def __init__(self, title, start):\n",
    "        self.id = str(id(self))\n",
    "        self.start = start\n",
    "        self.title = title\n",
    "        self.text = \"\"\n",
    "        self.children = []\n",
    "        self.json = {}\n",
    "\n",
    "        self.getText()\n",
    "        self.getSummary()\n",
    "\n",
    "    def addChild(self, other):\n",
    "        self.children.append(other)\n",
    "\n",
    "    def getJson(self):\n",
    "        self.json[self.id] = {}\n",
    "        self.json[self.id][\"start\"] = self.start\n",
    "        self.json[self.id][\"title\"] = self.title\n",
    "        self.json[self.id][\"text\"] = self.text\n",
    "        self.json[self.id][\"children\"] = [child.id for child in self.children]\n",
    "        return self.json\n",
    "\n",
    "    def getText(self):\n",
    "        #TODO Use PyPDF to get the text based on self.start\n",
    "        self.text = self.title\n",
    "\n",
    "    def getSummary(self):\n",
    "        #TODO Use GPT to get the summary of text\n",
    "        self.text = self.title\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Title: {self.title}\\n' \\\n",
    "               f'Text: {self.text}\\n' \\\n",
    "               f'Children: {[child.title for child in self.children]}\\n'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T19:32:17.908673800Z",
     "start_time": "2023-10-14T19:32:17.902913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'1660826770768': {'start': 'START',\n   'title': 'Attention Is All You Need',\n   'text': '',\n   'children': ['1660827658064',\n    '1660827658384',\n    '1660827658576',\n    '1660827660624',\n    '1660827660880',\n    '1660827662224',\n    '1660827663248']}},\n {'1660827658064': {'start': IndirectObject(136, 0, 1660825721360),\n   'title': 'Introduction',\n   'text': '',\n   'children': []}},\n {'1660827658384': {'start': IndirectObject(136, 0, 1660825721360),\n   'title': 'Background',\n   'text': '',\n   'children': []}},\n {'1660827658576': {'start': IndirectObject(136, 0, 1660825721360),\n   'title': 'Model Architecture',\n   'text': '',\n   'children': ['1660827658768',\n    '1660827658960',\n    '1660827659792',\n    '1660827660048',\n    '1660827660304']}},\n {'1660827658768': {'start': IndirectObject(169, 0, 1660825721360),\n   'title': 'Encoder and Decoder Stacks',\n   'text': '',\n   'children': []}},\n {'1660827658960': {'start': IndirectObject(169, 0, 1660825721360),\n   'title': 'Attention',\n   'text': '',\n   'children': ['1660827659152', '1660827659344', '1660827659536']}},\n {'1660827659152': {'start': IndirectObject(186, 0, 1660825721360),\n   'title': 'Scaled Dot-Product Attention',\n   'text': '',\n   'children': []}},\n {'1660827659344': {'start': IndirectObject(186, 0, 1660825721360),\n   'title': 'Multi-Head Attention',\n   'text': '',\n   'children': []}},\n {'1660827659536': {'start': IndirectObject(211, 0, 1660825721360),\n   'title': 'Applications of Attention in our Model',\n   'text': '',\n   'children': []}},\n {'1660827659792': {'start': IndirectObject(211, 0, 1660825721360),\n   'title': 'Position-wise Feed-Forward Networks',\n   'text': '',\n   'children': []}},\n {'1660827660048': {'start': IndirectObject(211, 0, 1660825721360),\n   'title': 'Embeddings and Softmax',\n   'text': '',\n   'children': []}},\n {'1660827660304': {'start': IndirectObject(224, 0, 1660825721360),\n   'title': 'Positional Encoding',\n   'text': '',\n   'children': []}},\n {'1660827660624': {'start': IndirectObject(224, 0, 1660825721360),\n   'title': 'Why Self-Attention',\n   'text': '',\n   'children': []}},\n {'1660827660880': {'start': IndirectObject(237, 0, 1660825721360),\n   'title': 'Training',\n   'text': '',\n   'children': ['1660827661200',\n    '1660827661456',\n    '1660827661712',\n    '1660827661968']}},\n {'1660827661200': {'start': IndirectObject(237, 0, 1660825721360),\n   'title': 'Training Data and Batching',\n   'text': '',\n   'children': []}},\n {'1660827661456': {'start': IndirectObject(237, 0, 1660825721360),\n   'title': 'Hardware and Schedule',\n   'text': '',\n   'children': []}},\n {'1660827661712': {'start': IndirectObject(237, 0, 1660825721360),\n   'title': 'Optimizer',\n   'text': '',\n   'children': []}},\n {'1660827661968': {'start': IndirectObject(237, 0, 1660825721360),\n   'title': 'Regularization',\n   'text': '',\n   'children': []}},\n {'1660827662224': {'start': IndirectObject(262, 0, 1660825721360),\n   'title': 'Results',\n   'text': '',\n   'children': ['1660827662480', '1660827662736', '1660827662992']}},\n {'1660827662480': {'start': IndirectObject(262, 0, 1660825721360),\n   'title': 'Machine Translation',\n   'text': '',\n   'children': []}},\n {'1660827662736': {'start': IndirectObject(262, 0, 1660825721360),\n   'title': 'Model Variations',\n   'text': '',\n   'children': []}},\n {'1660827662992': {'start': IndirectObject(294, 0, 1660825721360),\n   'title': 'English Constituency Parsing',\n   'text': '',\n   'children': []}},\n {'1660827663248': {'start': IndirectObject(307, 0, 1660825721360),\n   'title': 'Conclusion',\n   'text': '',\n   'children': []}}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_graph(pdf_path):\n",
    "    pdf_file = open(pdf_path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    root = SectionNode(\"Attention Is All You Need\", \"START\")\n",
    "    get_bookmark(root, pdf_reader.outline)\n",
    "\n",
    "    return root\n",
    "\n",
    "\n",
    "def get_bookmark(root, outline):\n",
    "    new = None\n",
    "\n",
    "    for item in outline:\n",
    "\n",
    "        if isinstance(item, list):\n",
    "            get_bookmark(new, item)\n",
    "        else:\n",
    "            new = SectionNode(item.title, item.page)\n",
    "            root.addChild(new)\n",
    "\n",
    "\n",
    "def get_json_output(json_output, root):\n",
    "    json_output.append(root.getJson())\n",
    "    for child in root.children:\n",
    "        get_json_output(json_output, child)\n",
    "\n",
    "\n",
    "def main(pdf_file):\n",
    "    root = create_graph(pdf_file)\n",
    "    json_output = []\n",
    "    get_json_output(json_output, root)\n",
    "    return json_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T19:32:18.378734500Z",
     "start_time": "2023-10-14T19:32:18.295756200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(root)\n",
    "\n",
    "for child in root.children:\n",
    "    print(child)\n",
    "\n",
    "    if child.children:\n",
    "        for subchild in child.children:\n",
    "            print(subchild)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "child_intro = root.children[0]\n",
    "child_back = root.children[1]\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "print(pdf_reader.outline,'\\n\\n')\n",
    "pdf_reader.get_object(child_intro.start).get('/Contents')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outline_dict = {\n",
    "        '/Page': PyPDF2.generic.IndirectObject(186, 0, 2926067309264),\n",
    "        '/Left': 108,\n",
    "        '/Top': 166.913\n",
    "    }\n",
    "\n",
    "page_reference = outline_dict['/Page']\n",
    "left = outline_dict['/Left']\n",
    "top = outline_dict['/Top']\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "page_number = pdf_reader.get_object(page_reference).get('/Contents')#.get('/MediaBox')\n",
    "page_number = page_number.getPageNumber()\n",
    "\n",
    "pdf_page = pdf_reader.getPage(page_number)\n",
    "\n",
    "x0, y0 = left, top\n",
    "x1, y1 = left + 10, top + 10\n",
    "\n",
    "page_text = pdf_page.extractText()\n",
    "extracted_text = \"\"\n",
    "for line in page_text.split('\\n'):\n",
    "    if x0 < left and x1 > left and y0 < top and y1 > top:\n",
    "        extracted_text += line + '\\n'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pdf2text(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        pdf_text = ''\n",
    "        for page_number in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_number]\n",
    "            pdf_text += page.extract_text(x_tolerance=2, y_tolerance=5, layout=False).strip()\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "def count_tokens(history: list):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = 0\n",
    "    for message in history:\n",
    "        num_tokens += 4\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += -1\n",
    "    num_tokens += 2\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def count_tokens_text(text: str):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def user_said(content, history):\n",
    "    history.append({\"role\":\"user\", \"content\":content})\n",
    "\n",
    "def assistant_said(content, history):\n",
    "    history.append({\"role\":\"assistant\", \"content\":content})\n",
    "\n",
    "def ask_chatgpt(user, history, system=None, new_chat=False, max_tokens=256, only_response=False, temp=0, model='gpt-3.5-turbo'):\n",
    "\n",
    "    history = [] if new_chat else history\n",
    "\n",
    "    if system and new_chat:\n",
    "        history.append({\"role\":\"system\", \"content\":system})\n",
    "    user_said(user, history)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=model,\n",
    "      messages=history,\n",
    "      temperature=temp,\n",
    "      max_tokens=max_tokens,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    response = response['choices'][0]['message']['content']\n",
    "\n",
    "    if only_response:\n",
    "        return response\n",
    "    else:\n",
    "        assistant_said(response, history)\n",
    "        return response, history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = pdf2text(pdf_file)\n",
    "print(text, '\\n\\n', count_tokens_text(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "system = f'Act as a professional scientist that reviews article.'\n",
    "article = f'article: {text}'\n",
    "\n",
    "prompt = f'{article}.\\nObjective: List sections and subsections of the article. To find those sections, include several exact words of the article that followed each section and subsection.'\n",
    "\n",
    "response, history = ask_chatgpt(prompt, history=[], system=system, new_chat=True, max_tokens=1000, temp=0, model='gpt-3.5-turbo-16k')\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text.find('Scaled Dot-Product Attention ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "section2text = {}\n",
    "sections_list = response.strip().split('\\n')\n",
    "section_indexes = []\n",
    "\n",
    "for section in sections_list:\n",
    "    section_indexes.append(text.find(section))\n",
    "\n",
    "print(section_indexes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text[20000:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text[2859:4780]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
